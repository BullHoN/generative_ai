{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ffad1240-046c-4378-b793-fed26ee69957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "[0.4915733]\n",
      "Epoch 0, Loss: 0.4435\n",
      "Epoch 100, Loss: 0.2426\n",
      "Epoch 200, Loss: 0.2426\n",
      "Epoch 300, Loss: 0.2426\n",
      "Epoch 400, Loss: 0.2426\n",
      "Epoch 500, Loss: 0.2426\n",
      "Epoch 600, Loss: 0.2426\n",
      "Epoch 700, Loss: 0.2426\n",
      "Epoch 800, Loss: 0.2426\n",
      "Epoch 900, Loss: 0.2426\n",
      "Predictions:\n",
      "0 is Even\n",
      "1 is Even\n",
      "2 is Even\n",
      "3 is Even\n",
      "4 is Even\n",
      "5 is Odd\n",
      "6 is Odd\n",
      "7 is Odd\n",
      "8 is Odd\n",
      "9 is Odd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of sigmoid for backpropagation\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# Training data (input: number, output: 1 if even, 0 if odd)\n",
    "X = np.array([[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]])\n",
    "y = np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
    "\n",
    "print(y.shape)\n",
    "\n",
    "# Initialize weights and bias randomly\n",
    "weights = np.random.rand(1)\n",
    "\n",
    "print(weights)\n",
    "bias = np.random.rand(1)\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Training loop\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    z = np.dot(X, weights) + bias\n",
    "\n",
    "    predictions = sigmoid(z)\n",
    "\n",
    "    # print(predictions)\n",
    "    # Calculate the error (loss)\n",
    "    loss = np.mean((predictions - y) ** 2)\n",
    "\n",
    "    # Backpropagation\n",
    "    d_loss = (predictions - y)  # Derivative of MSE loss\n",
    "    # print(d_loss.shape,predictions.shape,y.shape)\n",
    "    \n",
    "    d_predictions = d_loss * sigmoid_derivative(z)\n",
    "    \n",
    "    # Update weights and bias\n",
    "    weights -= learning_rate * np.dot(X.T, d_predictions).flatten()\n",
    "\n",
    "    bias -= learning_rate * np.sum(d_predictions)\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Test the trained model\n",
    "def predict(number):\n",
    "    result = sigmoid(np.dot(number, weights) + bias)\n",
    "    return \"Even\" if result >= 0.5 else \"Odd\"\n",
    "\n",
    "# Test cases\n",
    "print(\"Predictions:\")\n",
    "for num in range(10):\n",
    "    print(f\"{num} is {predict(np.array([num]))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b0c15a-e7c8-488c-92b1-e0d1737105a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
